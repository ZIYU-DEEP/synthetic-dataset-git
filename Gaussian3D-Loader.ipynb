{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T21:49:25.886002Z",
     "start_time": "2020-07-15T21:49:25.882373Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T22:11:51.018253Z",
     "start_time": "2020-07-15T22:11:51.016307Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################################################################\n",
    "# Helper Functions\n",
    "# #########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T22:07:12.869610Z",
     "start_time": "2020-07-15T22:07:12.861704Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_gaussian_train(normal_mu, abnormal_mu, split, random_state):\n",
    "    \"\"\"\n",
    "    Get the data and scaler used for training the model.\n",
    "    \n",
    "    Inputs:\n",
    "        normal_mu: (str) in a format like '1_1_1', indicating the mean for the normal\n",
    "        abnormal_mu: (str) in a format like '1_1_1', indicating the mean for the abnormal\n",
    "        split: (float) the ratio for test / train\n",
    "        random_state: (int) the seed for randomness\n",
    "    \n",
    "    Return:\n",
    "        X_train, X_test: (np.array) with a shape of (N_instances, 3)\n",
    "        y_train, y_test: (np.array) with a shape of (N_instances,)\n",
    "        scaler: (sklearn model) can be used later to scale evaluation data\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initialize for Gaussians\n",
    "    cov = [[0.1, 0, 0], \n",
    "           [0, 0.1, 0], \n",
    "           [0, 0, 0.1]]\n",
    "    normal_mu = [int(i) for i in normal_mu.split('_')]\n",
    "    abnormal_mu = [int(i) for i in abnormal_mu.split('_')]\n",
    "        \n",
    "    # Generate X_normal\n",
    "    X_normal = np.random.multivariate_normal(normal_mu, cov, 6000)\n",
    "    y_normal = np.zeros(X_normal.shape[0])\n",
    "        \n",
    "    # Generate X_abnormal and concatenate data\n",
    "    if abnormal_mu:\n",
    "        # Generate X_abnormal\n",
    "        X_abnormal = np.random.multivariate_normal(abnormal_mu, cov, 6000)\n",
    "        y_abnormal = np.ones(X_abnormal.shape[0])\n",
    "            \n",
    "        # Concatenate\n",
    "        X = np.vstack((X_normal, X_abnormal))\n",
    "        y = np.hstack((y_normal, y_abnormal))\n",
    "            \n",
    "    else:\n",
    "        # No need X_abnormal\n",
    "        X = X_normal\n",
    "        y = y_normal\n",
    "        \n",
    "    # Do train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=split,\n",
    "                                                        random_state=random_state,\n",
    "                                                        stratify=y)\n",
    "            \n",
    "            \n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test) \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T21:49:31.133814Z",
     "start_time": "2020-07-15T21:49:31.128344Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_ball(r, mu):\n",
    "    \"\"\"\n",
    "    Generate a set of data points surrounding a point like a ball.\n",
    "    \n",
    "    Inputs:\n",
    "        r: (float) distance between the trained normal and the trained\n",
    "           abnormal; used as the radius here\n",
    "        mu: (np.array) a 3d array specifying the mu for trained normal\n",
    "            or the trained abnormal data\n",
    "        \n",
    "    Returns:\n",
    "        result: (list) a list a 3d arrays indicating the mean for abnormal\n",
    "                data to test\n",
    "    \"\"\"\n",
    "    thetas = range(0, 360, 60)\n",
    "    phis = range(0, 360, 60)\n",
    "    pairs = [(theta, phi) for theta in thetas for phi in phis]\n",
    "    \n",
    "    result = []\n",
    "    for pair in pairs:\n",
    "        theta, phi = pair\n",
    "        cord = [sin(theta) * cos(phi) * r + mu[0], \n",
    "                sin(theta) * sin(phi) * r + mu[1], \n",
    "                cos(theta) * r + mu[2]]\n",
    "        if cord in result:\n",
    "            continue\n",
    "        result.append(cord)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T22:07:08.636352Z",
     "start_time": "2020-07-15T22:07:08.631805Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################################################################\n",
    "# 0. Base Loader\n",
    "# #########################################################################\n",
    "class BaseLoader(ABC):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_set = None  # must be of type torch.utils.data.Dataset\n",
    "        self.test_set = None  # must be of type torch.utils.data.Dataset\n",
    "\n",
    "    @abstractmethod\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle_train=True,\n",
    "                shuffle_test=False,\n",
    "                num_workers: int = 0) -> (DataLoader, DataLoader):\n",
    "        \"\"\"Implement data loaders of type torch.utils.data.DataLoader for train_set and test_set.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T21:49:34.035181Z",
     "start_time": "2020-07-15T21:49:34.028170Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################################################################\n",
    "# 1. Gaussian3D Dataset for Training\n",
    "# #########################################################################\n",
    "class Gaussian3DDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 normal_mu: str='1_-1_1',\n",
    "                 abnormal_mu: str='1_1_1',  # If unsupervised, do not specify\n",
    "                 train: bool=True,\n",
    "                 split: int=0.2,\n",
    "                 random_state: int=42):\n",
    "        super(Dataset, self).__init__()\n",
    "        \n",
    "        # Get the data for training and test\n",
    "        X_train, X_test, y_train, y_test, _ = gen_gaussian_train(normal_mu, \n",
    "                                                                 abnormal_mu, \n",
    "                                                                 split, \n",
    "                                                                 random_state)\n",
    "        \n",
    "        # Transform to tensors\n",
    "        if train:\n",
    "            self.X = torch.tensor(X_train, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y_train, dtype=torch.float32)\n",
    "        else:\n",
    "            self.X = torch.tensor(X_test, dtype=torch.float32)\n",
    "            self.y = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample, target = self.X[index], int(self.y[index])\n",
    "        return sample, target, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T21:58:28.010495Z",
     "start_time": "2020-07-15T21:58:28.004953Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################################################################\n",
    "# 2. Gaussian3D Loader for Training\n",
    "# #########################################################################\n",
    "class Gaussian3DLoader(BaseLoader):\n",
    "    def __init__(self,\n",
    "                 normal_mu: str='1_-1_1',\n",
    "                 abnormal_mu: str='1_1_1',  # If unsupervised, do not specify\n",
    "                 split: int=0.2,\n",
    "                 random_state: int=42):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Get train set\n",
    "        self.train_set = Gaussian3DDataset(normal_mu,\n",
    "                                           abnormal_mu,\n",
    "                                           True,\n",
    "                                           split,\n",
    "                                           random_state)\n",
    "\n",
    "        self.test_set = Gaussian3DDataset(normal_mu,\n",
    "                                          abnormal_mu,\n",
    "                                          False,\n",
    "                                          split,\n",
    "                                          random_state)\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int=128,\n",
    "                shuffle_train: bool=True,\n",
    "                shuffle_test: bool=False,\n",
    "                num_workers: int = 0):\n",
    "        train_loader = DataLoader(dataset=self.train_set,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=shuffle_train,\n",
    "                                  num_workers=num_workers,\n",
    "                                  drop_last=True)\n",
    "        test_loader = DataLoader(dataset=self.test_set,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle_test,\n",
    "                                 num_workers=num_workers,\n",
    "                                 drop_last=False)\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T21:58:29.940926Z",
     "start_time": "2020-07-15T21:58:29.933296Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################################################################\n",
    "# 3. Gaussian3D Dataset for Eval (Only load abnormal data!)\n",
    "# #########################################################################\n",
    "class Gaussian3DDatasetEval(Dataset):\n",
    "    def __init__(self,\n",
    "                 abnormal_mu_test,\n",
    "                 normal_mu_train: str='1_-1_1',\n",
    "                 abnormal_mu_train: str='1_1_1',\n",
    "                 split: int=0.2,\n",
    "                 random_state: int=42):\n",
    "        super(Dataset, self).__init__()\n",
    "        \n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        # Get the scaler used for training\n",
    "        _, _, _, _, scaler = gen_gaussian_train(normal_mu_train,\n",
    "                                                abnormal_mu_train,\n",
    "                                                split, random_state)\n",
    "        \n",
    "        # Generate abnormal X to test\n",
    "        cov = [[0.1, 0, 0], [0, 0.1, 0], [0, 0, 0.1]]\n",
    "        X = np.random.multivariate_normal(abnormal_mu_test, cov, 6000)\n",
    "        y = np.ones(X.shape[0])\n",
    "        \n",
    "        # Normalize the abnormal X\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        # Transform to tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample, target = self.X[index], int(self.y[index])\n",
    "        return sample, target, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T21:58:30.818500Z",
     "start_time": "2020-07-15T21:58:30.813305Z"
    }
   },
   "outputs": [],
   "source": [
    "# #########################################################################\n",
    "# 4. Gaussian3D Loader for Eval\n",
    "# #########################################################################\n",
    "class Gaussian3DLoaderEval(BaseLoader):\n",
    "    def __init__(self,\n",
    "                 abnormal_mu_test,\n",
    "                 normal_mu_train: str='1_-1_1',\n",
    "                 abnormal_mu_train: str='1_1_1',\n",
    "                 split: int=0.2,\n",
    "                 random_state: int=42):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Get train set\n",
    "        self.all_set = Gaussian3DDatasetEval(abnormal_mu_test,\n",
    "                                             normal_mu_train,\n",
    "                                             abnormal_mu_train,\n",
    "                                             split,\n",
    "                                             random_state)\n",
    "\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int=128,\n",
    "                shuffle: bool=False,\n",
    "                num_workers: int=0):\n",
    "        all_loader = DataLoader(dataset=self.all_set,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=num_workers,\n",
    "                                drop_last=False)\n",
    "        return all_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################################################\n",
    "# 2. ED Dataset for Eval (Only load abnormal data!)\n",
    "# #########################################################################\n",
    "class edDatasetEval(Dataset):\n",
    "    def __init__(self,\n",
    "                 root: str='../../data/processed/',\n",
    "                 abnormal_filename: str='X_data_y1_below_2_new.npy'):\n",
    "        super(Dataset, self).__init__()\n",
    "\n",
    "        # Initialization\n",
    "        self.root = Path(root)\n",
    "        self.abnormal_path = self.root / abnormal_filename\n",
    "        self.train = train\n",
    "        self.X = np.load(self.abnormal_path)\n",
    "        self.y = np.ones(X_abnormal.shape[0])\n",
    "\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample, target = self.X[index], int(self.y[index])\n",
    "        return sample, target, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "# #########################################################################\n",
    "# 3. ED Loader for Eval\n",
    "# #########################################################################\n",
    "class edLoaderEval(BaseLoader):\n",
    "    def __init__(self,\n",
    "                 root: str='../../data/processed/',\n",
    "                 abnormal_filename: str='X_data_y1_below_2_new.npy',\n",
    "                 random_state: int=42):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Get train set\n",
    "        self.all_set = edDataset(root=self.root,\n",
    "                                   abnormal_filename=abnormal_filename)\n",
    "\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle=False,\n",
    "                num_workers: int = 0) -> (DataLoader, DataLoader):\n",
    "        all_loader = DataLoader(dataset=self.all_set,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=shuffle,\n",
    "                                  num_workers=num_workers,\n",
    "                                  drop_last=False)\n",
    "        return all_loader\n",
    "\n",
    "\n",
    "# #########################################################################\n",
    "# 3. ED Loader for Training\n",
    "# #########################################################################\n",
    "class edLoader(BaseLoader):\n",
    "    def __init__(self,\n",
    "                 root: str='../../data/processed/',\n",
    "                 normal_filename: str='X_data_y0_below_2_new.npy',\n",
    "                 abnormal_filename: str='',  # If unsupervised, do not specify\n",
    "                 split: int=0.2,\n",
    "                 random_state: int=42):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Get train set\n",
    "        self.train_set = edDataset(root=self.root,\n",
    "                                   normal_filename=normal_filename,\n",
    "                                   abnormal_filename=abnormal_filename,\n",
    "                                   train=True,\n",
    "                                   split=split)\n",
    "\n",
    "        self.test_set = edDataset(root=self.root,\n",
    "                                  normal_filename=normal_filename,\n",
    "                                  abnormal_filename=abnormal_filename,\n",
    "                                  train=False,\n",
    "                                  split=split)\n",
    "\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle_train=True,\n",
    "                shuffle_test=False,\n",
    "                num_workers: int = 0) -> (DataLoader, DataLoader):\n",
    "        train_loader = DataLoader(dataset=self.train_set,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=shuffle_train,\n",
    "                                  num_workers=num_workers,\n",
    "                                  drop_last=True)\n",
    "        test_loader = DataLoader(dataset=self.test_set,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle_test,\n",
    "                                 num_workers=num_workers,\n",
    "                                 drop_last=False)\n",
    "        return train_loader, test_loader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
